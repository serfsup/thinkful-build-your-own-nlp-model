{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Build your own NLP model\n",
    "\n",
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes\n",
    "4. Assess your models using cross-validation and determine whether one model performed better\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points\n",
    "\n",
    "Write up your report in a Jupyter notebook. Be sure to explicitly justify the choices you make throughout, and submit it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:31.196303Z",
     "start_time": "2019-07-26T18:54:27.641584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import data science environment.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import scipy\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import shakespeare, stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:31.216735Z",
     "start_time": "2019-07-26T18:54:31.203215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \"\"\"Function to strip all characters except letters in words.\"\"\"\n",
    "    text = re.sub(r'--', ' ', text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(\"[\\<].*?[\\>]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:31.238769Z",
     "start_time": "2019-07-26T18:54:31.222687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import texts\n",
    "much_ado = open(\"Much Ado About Nothing.txt\", encoding='utf-16')\n",
    "romeo = open(\"Romeo and Juliet.txt\", encoding='utf-16')\n",
    "\n",
    "# Read the data.\n",
    "much_ado_raw = much_ado.read()\n",
    "romeo_raw = romeo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:31.275699Z",
     "start_time": "2019-07-26T18:54:31.246479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the data.\n",
    "much_ado_clean = text_cleaner(much_ado_raw)\n",
    "romeo_clean = text_cleaner(romeo_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:31.296920Z",
     "start_time": "2019-07-26T18:54:31.280638Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I learn in this letter that Don Pedro of Arragon comes this night to Messina. He is very near by this: he was not three leagues off when I left him. How many gentlemen have you lost in this action? But few of any sort, and none of name. A victory is twice itself when the achiever brings home full numbers. I find here that Don Pedro hath bestowed much honour on a young Florentine called Claudio. Much deserved on his part and equally remembered by Don Pedro. He hath borne himself beyond the promise of his age, doing in the figure of a lamb the feats of a lion: he hath indeed better bettered expectation than you must expect of me to tell you how. He hath an uncle here in Messina will be very much glad of it. I have already delivered him letters, and there appears much joy in him; even so much that joy could not show itself modest enough without a badge of bitterness. Did he break out into tears? In great measure. A kind overflow of kindness. There are no faces truer than those that are so'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "much_ado_clean[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:31.314627Z",
     "start_time": "2019-07-26T18:54:31.304023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Two households, both alike in dignity, In fair Verona, where we lay our scene, From ancient grudge break to new mutiny, Where civil blood makes civil hands unclean. From forth the fatal loins of these two foes A pair of star-cross'd lovers take their life; Whose misadventur'd piteous overthrows Do with their death bury their parents' strife. The fearful passage of their death-mark'd love, And the continuance of their parents' rage, Which, but their children's end, nought could remove, Is now the two hours' traffick of our stage; The which if you with patient ears attend, What here shall miss, our toil shall strive to mend. Gregory, o' my word, we'll not carry coals. No. for then we should be colliers. I mean, an we be in choler, we'll draw. Ay, while you live, draw your neck out o' the collar. I strike quickly, being moved. But thou art not quickly moved to strike. A dog of the house of Montague moves me. To move is to stir, and to be valiant is to stand; therefore, if thou art moved, \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "romeo_clean[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:41.118362Z",
     "start_time": "2019-07-26T18:54:31.319182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parse the data. This can take some time.\n",
    "nlp = spacy.load('en')\n",
    "much_ado_doc = nlp(much_ado_clean)\n",
    "romeo_doc = nlp(romeo_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:41.159902Z",
     "start_time": "2019-07-26T18:54:41.121646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(I, learn, in, this, letter, that, Don, Pedro,...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(He, is, very, near, by, this, :, he, was, not...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(How, many, gentlemen, have, you, lost, in, th...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(But, few, of, any, sort, ,, and, none, of, na...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(A, victory, is, twice, itself, when, the, ach...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0  (I, learn, in, this, letter, that, Don, Pedro,...  Much Ado\n",
       "1  (He, is, very, near, by, this, :, he, was, not...  Much Ado\n",
       "2  (How, many, gentlemen, have, you, lost, in, th...  Much Ado\n",
       "3  (But, few, of, any, sort, ,, and, none, of, na...  Much Ado\n",
       "4  (A, victory, is, twice, itself, when, the, ach...  Much Ado"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "much_ado_sents = [[sent, \"Much Ado\"] for sent in much_ado_doc.sents]\n",
    "romeo_sents = [[sent, \"Romeo\"] for sent in romeo_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two plays into one data frame.\n",
    "sentences = pd.DataFrame(much_ado_sents + romeo_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:41.193637Z",
     "start_time": "2019-07-26T18:54:41.163102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up bag of words function for each text.\n",
    "def bag_of_words(text):\n",
    "    \"\"\"Counts the total number of instances of each word in a doc.\"\"\"\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \"\"\"The 'sentences' variable is a data frame; common_words is a set.\"\"\"\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        if i % 100 == 0:\n",
    "            print('Processing row {}'.format(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:54:41.270627Z",
     "start_time": "2019-07-26T18:54:41.195639Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up bags for each play.\n",
    "much_ado_words = bag_of_words(much_ado_doc)\n",
    "romeo_words = bag_of_words(romeo_doc)\n",
    "\n",
    "# Make bag of common words.\n",
    "common_words = set(much_ado_words + romeo_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:23.810053Z",
     "start_time": "2019-07-26T18:54:41.281539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 100\n",
      "Processing row 200\n",
      "Processing row 300\n",
      "Processing row 400\n",
      "Processing row 500\n",
      "Processing row 600\n",
      "Processing row 700\n",
      "Processing row 800\n",
      "Processing row 900\n",
      "Processing row 1000\n",
      "Processing row 1100\n",
      "Processing row 1200\n",
      "Processing row 1300\n",
      "Processing row 1400\n",
      "Processing row 1500\n",
      "Processing row 1600\n",
      "Processing row 1700\n",
      "Processing row 1800\n",
      "Processing row 1900\n",
      "Processing row 2000\n",
      "Processing row 2100\n",
      "Processing row 2200\n",
      "Processing row 2300\n",
      "Processing row 2400\n",
      "Processing row 2500\n",
      "Processing row 2600\n",
      "Processing row 2700\n",
      "Processing row 2800\n",
      "Processing row 2900\n",
      "Processing row 3000\n",
      "Processing row 3100\n",
      "Processing row 3200\n",
      "Processing row 3300\n",
      "Processing row 3400\n",
      "Processing row 3500\n",
      "Processing row 3600\n",
      "Processing row 3700\n",
      "Processing row 3800\n",
      "Processing row 3900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show</th>\n",
       "      <th>innocent</th>\n",
       "      <th>sit</th>\n",
       "      <th>ape</th>\n",
       "      <th>boy</th>\n",
       "      <th>one</th>\n",
       "      <th>bestow</th>\n",
       "      <th>argument</th>\n",
       "      <th>sorry</th>\n",
       "      <th>would</th>\n",
       "      <th>...</th>\n",
       "      <th>thou</th>\n",
       "      <th>get</th>\n",
       "      <th>make</th>\n",
       "      <th>count</th>\n",
       "      <th>exceed</th>\n",
       "      <th>set</th>\n",
       "      <th>wonder</th>\n",
       "      <th>take</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, learn, in, this, letter, that, Don, Pedro,...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(He, is, very, near, by, this, :, he, was, not...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(How, many, gentlemen, have, you, lost, in, th...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(But, few, of, any, sort, ,, and, none, of, na...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(A, victory, is, twice, itself, when, the, ach...</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 697 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  show innocent sit ape boy one bestow argument sorry would  ... thou get  \\\n",
       "0    0        0   0   0   0   0      0        0     0     0  ...    0   0   \n",
       "1    0        0   0   0   0   0      0        0     0     0  ...    0   0   \n",
       "2    0        0   0   0   0   0      0        0     0     0  ...    0   0   \n",
       "3    0        0   0   0   0   0      0        0     0     0  ...    0   0   \n",
       "4    0        0   0   0   0   0      0        0     0     0  ...    0   0   \n",
       "\n",
       "  make count exceed set wonder take  \\\n",
       "0    0     0      0   0      0    0   \n",
       "1    0     0      0   0      0    0   \n",
       "2    0     0      0   0      0    0   \n",
       "3    0     0      0   0      0    0   \n",
       "4    0     0      0   0      0    0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (I, learn, in, this, letter, that, Don, Pedro,...    Much Ado  \n",
       "1  (He, is, very, near, by, this, :, he, was, not...    Much Ado  \n",
       "2  (How, many, gentlemen, have, you, lost, in, th...    Much Ado  \n",
       "3  (But, few, of, any, sort, ,, and, none, of, na...    Much Ado  \n",
       "4  (A, victory, is, twice, itself, when, the, ach...    Much Ado  \n",
       "\n",
       "[5 rows x 697 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:24.392336Z",
     "start_time": "2019-07-26T19:18:23.812747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danmchenry/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9565772669220945\n",
      "\n",
      "Test set score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence', 'text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=15\n",
    "                                                   )\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: ', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:24.562665Z",
     "start_time": "2019-07-26T19:18:24.394583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2349, 695) (2349,)\n",
      "Training set score: 0.8437633035334184\n",
      "\n",
      "Test set score: 0.7273307790549169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danmchenry/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:28.990983Z",
     "start_time": "2019-07-26T19:18:24.565164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.7454235845040442\n",
      "\n",
      "Test set score: 0.6724137931034483\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:29.158405Z",
     "start_time": "2019-07-26T19:18:28.993567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Training set score: 0.8671775223499362\n",
      "\n",
      "Test set score: 0.7171136653895275\n"
     ]
    }
   ],
   "source": [
    "# SVM model, import packages.\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc)\n",
    "print('Training set score:', svc.score(X_train, y_train))\n",
    "print('\\nTest set score:', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:29.223333Z",
     "start_time": "2019-07-26T19:18:29.161367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Much Ado: [('I', 712), (\"'s\", 170), ('And', 116), ('man', 111), ('love', 90), ('good', 78), ('thou', 74), ('thee', 74), ('shall', 72), ('hath', 67), ('lord', 66), ('God', 63), ('Hero', 63), ('Claudio', 57), ('know', 56), ('Benedick', 56), ('But', 51), ('let', 51), ('prince', 51), ('like', 50), ('thy', 50), ('If', 49), ('lady', 48), (\"'ll\", 48), ('O', 46), ('come', 45), ('think', 45), ('What', 43), ('You', 43), ('Beatrice', 40), ('tell', 39), ('hear', 38), ('brother', 37), ('The', 37), ('To', 37), ('night', 35), ('No', 35), ('Signior', 33), ('cousin', 33), ('heart', 33), ('Come', 33), ('That', 33), ('Why', 32), ('sir', 31), ('Leonato', 30), ('daughter', 30), ('wit', 29), ('Well', 28), ('speak', 28), ('men', 28), ('In', 27), ('pray', 27), ('How', 25), ('Yea', 25), ('My', 23), ('Is', 23), ('answer', 23), ('true', 22), ('doth', 22), ('For', 22), ('morrow', 22), ('He', 21), ('A', 21), ('faith', 21), ('till', 21), ('hand', 21), ('Nay', 21), ('As', 21), ('She', 21), ('fashion', 20), ('old', 20), ('husband', 20), ('By', 19), ('day', 19), ('Lady', 18), ('bid', 18), ('said', 18), ('marry', 18), ('fool', 17), ('Margaret', 17), ('There', 16), ('Good', 16), ('die', 16), ('fair', 16), ('matter', 16), ('Count', 16), ('look', 16), ('We', 16), ('John', 16), ('So', 16), ('Don', 15), ('great', 15), ('It', 15), ('gentleman', 15), ('leave', 15), ('thank', 15), ('way', 15), ('wear', 15), ('death', 15), ('life', 15)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate word frequencies.\n",
    "def word_frequencies(text, include_stop=True):\n",
    "    \"\"\"A data frame that will keep track of word usage.\"\"\"\n",
    "    # Build a list of words.\n",
    "    # Strip out punctuation and stop words.\n",
    "    words = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            words.append(token.text)\n",
    "            \n",
    "    # Build and return a Counter object containing word counts.\n",
    "    return Counter(words)\n",
    "\n",
    "# The most frequent words:\n",
    "much_ado_freq = word_frequencies(\n",
    "    much_ado_doc, include_stop=False).most_common(100)\n",
    "print('Much Ado:', much_ado_freq)\n",
    "romeo_freq = word_frequencies(romeo_doc, include_stop=False).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:29.238032Z",
     "start_time": "2019-07-26T19:18:29.226753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique to Much Ado: {'Leonato', 'husband', 'matter', 'great', 'answer', 'wear', 'Beatrice', 'prince', 'gentleman', 'Benedick', 'bid', 'John', 'think', 'Margaret', 'Don', 'fool', 'till', 'brother', 'pray', 'Signior', 'cousin', 'leave', 'Well', 'marry', 'Nay', 'fashion', 'Good', 'way', 'said', 'daughter', 'He', 'thank', 'faith', 'Yea', 'Lady', 'There', 'She', 'Hero', 'Claudio', 'Count', 'wit'}\n",
      "Unique to Romeo: {'house', 'Tybalt', 'stay', 'Go', 'Or', 'heaven', 'tis', 'word', 'light', 'wilt', 'time', 'hast', 'face', 'Ay', 'sweet', 'find', 'art', 'Then', 'Now', 'Romeo', 'dead', 'Thou', 'Montague', 'Of', 'Which', 'Here', 'eyes', 'Paris', 'stand', 'tears', 'This', 'lie', 'Where', 'bed', 'With', 'gone', 'Juliet', 'nurse', 'dear', 'father', 'comes'}\n"
     ]
    }
   ],
   "source": [
    "# Pull out just the text from our frequency lists.\n",
    "much_ado_common = [pair[0] for pair in much_ado_freq]\n",
    "romeo_common = [pair[0] for pair in romeo_freq]\n",
    "\n",
    "# Use sets to find the unique values in each top 100.\n",
    "print('Unique to Much Ado:', set(much_ado_common) - set(romeo_common))\n",
    "print('Unique to Romeo:', set(romeo_common) - set(much_ado_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:29.341803Z",
     "start_time": "2019-07-26T19:18:29.241696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Much Ado: [('-PRON-', 877), ('man', 140), ('and', 116), ('love', 113), (\"'s\", 107), ('good', 105), ('be', 104), ('come', 99), ('thou', 86), ('know', 84), ('shall', 82), ('hath', 76), ('thee', 74), ('lord', 73), ('lady', 69), ('god', 68), ('let', 65), ('hero', 63), ('will', 61), ('think', 61), ('prince', 59), ('tell', 58), ('claudio', 57), ('benedick', 56), ('like', 52), ('thy', 52), ('but', 51), ('hear', 51), ('speak', 51), ('o', 49), ('if', 49), ('what', 43), ('signior', 42), ('beatrice', 40), ('brother', 39), ('marry', 39), ('night', 37), ('sir', 37), ('the', 37), ('to', 37), ('cousin', 36), ('heart', 36), ('no', 35), ('pray', 34), ('that', 33), ('why', 32), ('wit', 31), ('daughter', 31), ('leonato', 30), ('look', 29), ('say', 29), ('go', 28), ('well', 28), ('yea', 28), ('count', 28), ('master', 28), ('in', 27), ('swear', 27), ('die', 27), ('word', 26), ('hand', 26), ('answer', 26), ('how', 25), ('true', 25), ('leave', 24), ('faith', 24), ('doth', 24), ('nay', 24), ('bring', 22), ('fashion', 22), ('till', 22), ('thank', 22), ('for', 22), ('morrow', 22), ('a', 21), ('bear', 21), ('grace', 21), ('old', 21), ('husband', 21), ('as', 21), ('day', 21), ('wear', 20), ('bid', 20), ('eye', 20), ('sweet', 20), ('do', 19), ('great', 19), ('fool', 19), ('friend', 19), ('live', 19), ('fair', 19), ('by', 19), ('tis', 19), ('time', 18), ('lie', 18), ('thing', 18), ('gentleman', 17), ('father', 17), ('troth', 17), ('write', 17)]\n",
      "Romeo: [('-PRON-', 855), ('thou', 278), ('and', 228), (\"'s\", 193), ('thy', 166), ('o', 160), ('love', 156), ('be', 144), ('come', 139), ('thee', 135), ('romeo', 126), ('shall', 110), ('will', 103), ('good', 100), ('man', 99), ('what', 89), ('night', 88), ('to', 85), ('that', 79), ('death', 75), ('but', 75), ('the', 69), ('go', 68), ('hath', 63), ('day', 62), ('sir', 57), ('tybalt', 57), ('lady', 57), ('for', 56), ('art', 54), ('a', 53), ('let', 52), ('fair', 47), ('eye', 47), ('tell', 47), ('doth', 47), ('dead', 47), ('know', 45), ('lie', 45), ('juliet', 43), ('time', 42), ('like', 42), ('tis', 41), ('speak', 41), ('look', 40), ('sweet', 40), ('nurse', 40), ('hand', 38), ('marry', 38), ('heart', 37), ('word', 36), ('this', 36), ('in', 33), ('live', 33), ('as', 33), ('find', 33), ('god', 33), ('heaven', 31), ('where', 30), ('ay', 30), ('wilt', 30), ('or', 30), ('stay', 30), ('lord', 30), ('stand', 29), ('light', 29), ('of', 29), ('hast', 29), ('which', 28), ('true', 28), ('say', 28), ('old', 28), ('dear', 28), ('house', 27), ('how', 27), ('if', 27), ('so', 27), ('bed', 27), ('die', 27), ('think', 27), ('paris', 27), ('life', 26), ('hour', 26), ('hear', 26), ('by', 26), ('tear', 26), ('young', 26), ('father', 26), ('no', 25), ('montague', 25), ('why', 25), ('see', 25), ('give', 24), ('with', 24), ('then', 24), ('now', 24), ('slay', 24), ('away', 23), ('madam', 23), ('thing', 23)]\n",
      "Unique to Much Ado: {'friend', 'husband', 'answer', 'great', 'leonato', 'prince', 'wear', 'gentleman', 'troth', 'bid', 'benedick', 'hero', 'master', 'fool', 'write', 'brother', 'till', 'beatrice', 'yea', 'pray', 'cousin', 'signior', 'leave', 'claudio', 'well', 'fashion', 'morrow', 'grace', 'daughter', 'swear', 'bear', 'do', 'thank', 'faith', 'nay', 'bring', 'count', 'wit'}\n",
      "Unique to Romeo: {'house', 'stay', 'slay', 'away', 'paris', 'life', 'romeo', 'where', 'hour', 'heaven', 'tear', 'of', 'tybalt', 'or', 'wilt', 'light', 'hast', 'find', 'art', 'then', 'see', 'dead', 'juliet', 'which', 'ay', 'death', 'so', 'young', 'stand', 'bed', 'madam', 'montague', 'give', 'this', 'nurse', 'now', 'dear', 'with'}\n"
     ]
    }
   ],
   "source": [
    "# Utility function to calculate how frequently lemmas appear in the text.\n",
    "def lemma_frequencies(text, include_stop=True):\n",
    "    \"\"\"Function to identify lemma frequencies\"\"\"\n",
    "    # Build a list of lemmas.\n",
    "    # Strip out punctuation and stop words.\n",
    "    lemmas = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            lemmas.append(token.lemma_)\n",
    "            \n",
    "    # Build and return a Counter object containing word counts.\n",
    "    return Counter(lemmas)\n",
    "\n",
    "# Instantiate our list of most common lemmas.\n",
    "much_ado_lemma_freq = lemma_frequencies(\n",
    "    much_ado_doc, include_stop=False).most_common(100)\n",
    "romeo_lemma_freq = lemma_frequencies(\n",
    "    romeo_doc, include_stop=False).most_common(100)\n",
    "print('\\nMuch Ado:', much_ado_lemma_freq)\n",
    "print('Romeo:', romeo_lemma_freq)\n",
    "\n",
    "# Again, identify the lemmas common to one text but not the other.\n",
    "much_ado_lemma_common = [pair[0] for pair in much_ado_lemma_freq]\n",
    "romeo_lemma_common = [pair[0] for pair in romeo_lemma_freq]\n",
    "\n",
    "print('Unique to Much Ado:', set(much_ado_lemma_common) -\n",
    "      set(romeo_lemma_common))\n",
    "print('Unique to Romeo:', set(romeo_lemma_common) -\n",
    "      set(much_ado_lemma_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:29.364459Z",
     "start_time": "2019-07-26T19:18:29.345586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Much Ado About Nothing has 1685 sentences.\n",
      "Romeo and Juliet has 2230 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many sentences are in each play.\n",
    "sents_much_ado = list(much_ado_doc.sents)\n",
    "sents_romeo = list(romeo_doc.sents)\n",
    "\n",
    "print(\"Much Ado About Nothing has {} sentences.\".format(len(sents_much_ado)))\n",
    "print(\"Romeo and Juliet has {} sentences.\".format(len(sents_romeo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:29.526841Z",
     "start_time": "2019-07-26T19:18:29.369012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show</th>\n",
       "      <th>innocent</th>\n",
       "      <th>sit</th>\n",
       "      <th>ape</th>\n",
       "      <th>boy</th>\n",
       "      <th>one</th>\n",
       "      <th>bestow</th>\n",
       "      <th>argument</th>\n",
       "      <th>sorry</th>\n",
       "      <th>would</th>\n",
       "      <th>...</th>\n",
       "      <th>set</th>\n",
       "      <th>wonder</th>\n",
       "      <th>take</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>punct_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, learn, in, this, letter, that, Don, Pedro,...</td>\n",
       "      <td>Much Ado</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(He, is, very, near, by, this, :, he, was, not...</td>\n",
       "      <td>Much Ado</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(How, many, gentlemen, have, you, lost, in, th...</td>\n",
       "      <td>Much Ado</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(But, few, of, any, sort, ,, and, none, of, na...</td>\n",
       "      <td>Much Ado</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(A, victory, is, twice, itself, when, the, ach...</td>\n",
       "      <td>Much Ado</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  show innocent sit ape boy one bestow argument sorry would  ... set wonder  \\\n",
       "0    0        0   0   0   0   0      0        0     0     0  ...   0      0   \n",
       "1    0        0   0   0   0   0      0        0     0     0  ...   0      0   \n",
       "2    0        0   0   0   0   0      0        0     0     0  ...   0      0   \n",
       "3    0        0   0   0   0   0      0        0     0     0  ...   0      0   \n",
       "4    0        0   0   0   0   0      0        0     0     0  ...   0      0   \n",
       "\n",
       "  take                                      text_sentence text_source  \\\n",
       "0    0  (I, learn, in, this, letter, that, Don, Pedro,...    Much Ado   \n",
       "1    0  (He, is, very, near, by, this, :, he, was, not...    Much Ado   \n",
       "2    0  (How, many, gentlemen, have, you, lost, in, th...    Much Ado   \n",
       "3    0  (But, few, of, any, sort, ,, and, none, of, na...    Much Ado   \n",
       "4    0  (A, victory, is, twice, itself, when, the, ach...    Much Ado   \n",
       "\n",
       "  sent_length adv_count verb_count noun_count punct_count  \n",
       "0          16         0          2          2           1  \n",
       "1          18         3          3          1           2  \n",
       "2          10         1          2          2           1  \n",
       "3          11         0          0          3           2  \n",
       "4          13         2          2          4           1  \n",
       "\n",
       "[5 rows x 702 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy word_counts data frame as a form of version control.\n",
    "word_counts2 = word_counts\n",
    "\n",
    "# Add a column for the word counts in each sentence to the data frame.\n",
    "word_counts2['sent_length'] = word_counts2.text_sentence.map(lambda x: len(x))\n",
    "\n",
    "# Let's create a count for parts of speech.\n",
    "# Adverbs in each sentence.\n",
    "sentences2 = word_counts2.text_sentence\n",
    "adv_count = []\n",
    "for sent in sentences2:\n",
    "    advs = 0\n",
    "    for token in sent:\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "    adv_count.append(advs)\n",
    "    \n",
    "# Add adverbs column to data frame.\n",
    "word_counts2['adv_count'] = adv_count\n",
    "\n",
    "# Verbs in each sentence.\n",
    "verb_count = []\n",
    "for sent in sentences2:\n",
    "    verb = 0\n",
    "    for token in sent:\n",
    "        if token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "    verb_count.append(verb)\n",
    "    \n",
    "# Add verbs column to data frame.\n",
    "word_counts2['verb_count'] = verb_count\n",
    "\n",
    "# Nouns in each sentence:\n",
    "noun_count = []\n",
    "for sent in sentences2:\n",
    "    noun = 0\n",
    "    for token in sent:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "    noun_count.append(noun)\n",
    "    \n",
    "# Add nouns column to data frame.\n",
    "word_counts2['noun_count'] = noun_count\n",
    "\n",
    "# Punctuation marks in each sentence.\n",
    "punct_count = []\n",
    "for sent in sentences2:\n",
    "    punct = 0\n",
    "    for token in sent:\n",
    "        if token.pos_ == 'PUNCT':\n",
    "            punct +=1\n",
    "    punct_count.append(punct)\n",
    "    \n",
    "# Add punctuation column to data frame.\n",
    "word_counts2['punct_count'] = punct_count\n",
    "\n",
    "word_counts2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:30.076152Z",
     "start_time": "2019-07-26T19:18:29.529349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.8671775223499362\n",
      "\n",
      "Test set score:  0.7171136653895275\n"
     ]
    }
   ],
   "source": [
    "# Let's go back and re-try SVM with the new features.\n",
    "Y2 = word_counts2['text_source']\n",
    "X2 = np.array(word_counts2.drop(['text_sentence', 'text_source'], 1))\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X,Y,test_size=0.4,random_state=15)\n",
    "svm2 = LinearSVC()\n",
    "train2 = svm2.fit(X2_train, y2_train)\n",
    "print('Training set score: ', svm2.score(X2_train, y2_train))\n",
    "print('\\nTest set score: ', svm2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:30.153754Z",
     "start_time": "2019-07-26T19:18:30.081864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Much Ado</th>\n",
       "      <th>Romeo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Much Ado</th>\n",
       "      <td>400</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romeo</th>\n",
       "      <td>163</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        Much Ado  Romeo\n",
       "text_source                 \n",
       "Much Ado          400    280\n",
       "Romeo             163    723"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see this in crosstab.\n",
    "svm2_predicted = svm2.predict(X_test)\n",
    "pd.crosstab(y2_test, svm2_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:30.814694Z",
     "start_time": "2019-07-26T19:18:30.158735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9744572158365262\n",
      "\n",
      "Test set score: 0.6845466155810983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danmchenry/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Let's try the Random Forest again with the new features.\n",
    "rfc2 = ensemble.RandomForestClassifier()\n",
    "Y3 = word_counts2['text_source']\n",
    "X3 = np.array(word_counts2.drop(['text_sentence', 'text_source'], 1))\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3,\n",
    "                                                        Y3,\n",
    "                                                        test_size=0.4,\n",
    "                                                        random_state=15\n",
    "                                                       )\n",
    "\n",
    "train3 = rfc2.fit(X3_train, y3_train)\n",
    "\n",
    "print('Training set score: ', rfc2.score(X3_train, y3_train))\n",
    "print('\\nTest set score:', rfc2.score(X3_test, y3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:31.216389Z",
     "start_time": "2019-07-26T19:18:30.817954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>Much Ado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1\n",
       "0  I  Much Ado\n",
       "1     Much Ado\n",
       "2  l  Much Ado\n",
       "3  e  Much Ado\n",
       "4  a  Much Ado"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new variables that aren't spacy tokens.\n",
    "much_ado_tfidf = much_ado_clean\n",
    "romeo_tfidf = romeo_clean\n",
    "\n",
    "# Group into sentences.\n",
    "much_ado_tfidf_sents = [[sent, \"Much Ado\"] for sent in much_ado_tfidf]\n",
    "romeo_tfidf_sents = [[sent, \"Romeo\"] for sent in romeo_tfidf]\n",
    "\n",
    "# Combine sentences from two plays into one data frame.\n",
    "sentences_tfidf = pd.DataFrame(much_ado_tfidf_sents + romeo_tfidf_sents)\n",
    "sentences_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:18:32.355223Z",
     "start_time": "2019-07-26T19:18:31.219397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2349, 700) (2349,)\n",
      "Training set score: 0.8424861643252448\n",
      "\n",
      "Test set score: 0.7369093231162197\n"
     ]
    }
   ],
   "source": [
    "# Let's set up our model again.\n",
    "Y4 = word_counts2['text_source']\n",
    "X4 = np.array(word_counts2.drop(['text_sentence', 'text_source'], 1))\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4,\n",
    "                                                        Y4,\n",
    "                                                        test_size=0.4,\n",
    "                                                        random_state=15)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "train4 = lr.fit(X4_train, y4_train)\n",
    "print(X4_train.shape, y4_train.shape)\n",
    "print('Training set score:', lr.score(X4_train, y4_train))\n",
    "print('\\nTest set score:', lr.score(X4_test, y4_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying this many different ways with many Q & A Session visits with multiple mentors, I am unable to improve upon the results of these models. Some of the models do improve as we go on, but nothing close to the 5% improvement that is requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "969px",
    "right": "20px",
    "top": "106px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
